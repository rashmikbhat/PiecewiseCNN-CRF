{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40c3c61",
   "metadata": {},
   "source": [
    "# Piecewise Training for Semantic Segmentation\n",
    "This notebook demonstrates how to:\n",
    "1. Download and prepare the VOC 2012 dataset\n",
    "2. Install dependencies\n",
    "3. Configure dataset paths\n",
    "4. Visualize samples\n",
    "5. Train the piecewise segmentation model\n",
    "6. Evaluate and visualize results\n",
    "7. Run inference on a test image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f91a88",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "Run the following cell to install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision numpy pillow matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be658e2b",
   "metadata": {},
   "source": [
    "## 2. Download VOC 2012 Dataset\n",
    "Download from [VOC2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/) and extract it.\n",
    "Expected structure:\n",
    "```\n",
    "VOCdevkit/VOC2012/\n",
    "  ├── JPEGImages/\n",
    "  ├── SegmentationClass/\n",
    "  ├── ImageSets/Segmentation/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4b3eb",
   "metadata": {},
   "source": [
    "## 3. Configure Dataset Paths\n",
    "Update the paths below to point to your VOC2012 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/path/to/VOCdevkit/VOC2012/JPEGImages'\n",
    "label_dir = '/path/to/VOCdevkit/VOC2012/SegmentationClass'\n",
    "train_list = '/path/to/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt'\n",
    "val_list = '/path/to/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e34f0",
   "metadata": {},
   "source": [
    "## 4. Visualize a Sample Image and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a67a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Pick a random image from JPEGImages\n",
    "sample_img = random.choice([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
    "img_path = os.path.join(image_dir, sample_img)\n",
    "label_path = os.path.join(label_dir, sample_img.replace('.jpg', '.png'))\n",
    "\n",
    "img = Image.open(img_path)\n",
    "label = Image.open(label_path)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Image')\n",
    "axes[1].imshow(label)\n",
    "axes[1].set_title('Segmentation Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33dc01",
   "metadata": {},
   "source": [
    "## 5. Train the Piecewise Model\n",
    "This uses the implementation from `Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation` (model, trainer, dataset classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63991412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from piecewise_training.model import PiecewiseTrainedModel\n",
    "from piecewise_training.trainer import PiecewiseTrainer\n",
    "from piecewise_training.dataset import SegmentationDataset, RandomHorizontalFlip\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Config\n",
    "num_classes = 21\n",
    "batch_size = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Datasets\n",
    "train_dataset = SegmentationDataset(image_dir=image_dir, label_dir=label_dir, transform=RandomHorizontalFlip(), image_size=(512, 512))\n",
    "val_dataset = SegmentationDataset(image_dir=image_dir, label_dir=label_dir, image_size=(512, 512))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Model and trainer\n",
    "model = PiecewiseTrainedModel(num_classes=num_classes, crf_iterations=10, use_crf=True)\n",
    "trainer = PiecewiseTrainer(model=model, device=device, num_classes=num_classes, learning_rate=1e-3, weight_decay=5e-4)\n",
    "\n",
    "# Train\n",
    "history = trainer.train_piecewise(train_loader=train_loader, stage1_epochs=20, stage2_epochs=5, stage3_epochs=10, val_loader=val_loader)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'piecewise_model_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40465eb1",
   "metadata": {},
   "source": [
    "## 6. Evaluate and Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d14f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from piecewise_training.utils import plot_training_history\n",
    "plot_training_history(history, save_path='training_history.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d357b",
   "metadata": {},
   "source": [
    "## 7. Run Inference on a Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from piecewise_training.utils import visualize_segmentation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load('piecewise_model_final.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Load test image\n",
    "test_image_path = '/path/to/test/image.jpg'\n",
    "image = Image.open(test_image_path).convert('RGB').resize((512, 512))\n",
    "image_tensor = torch.from_numpy(np.array(image)).permute(2, 0, 1).float() / 255.0\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "image_tensor = (image_tensor - mean) / std\n",
    "image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    unary_output, crf_output = model(image_tensor, apply_crf=True)\n",
    "    prediction = crf_output.argmax(dim=1).squeeze(0)\n",
    "\n",
    "visualize_segmentation(image_tensor.squeeze(0), prediction.cpu(), prediction.cpu(), num_classes=num_classes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
