{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40c3c61",
   "metadata": {},
   "source": [
    "# Piecewise Training for Semantic Segmentation - Complete Pipeline\n",
    "This notebook demonstrates:\n",
    "1. Download and prepare VOC 2012 dataset\n",
    "2. Install dependencies\n",
    "3. Configure dataset paths\n",
    "4. Visualize samples\n",
    "5. Train the piecewise segmentation model\n",
    "6. Generate comprehensive evaluation reports\n",
    "7. Run inference on test images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f91a88",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "Run the following cell to install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision numpy pillow matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be658e2b",
   "metadata": {},
   "source": [
    "## 2. Download VOC 2012 Dataset\n",
    "Download from [VOC2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/) and extract it.\n",
    "Expected structure:\n",
    "```\n",
    "VOCdevkit/VOC2012/\n",
    "  ‚îú‚îÄ‚îÄ JPEGImages/\n",
    "  ‚îú‚îÄ‚îÄ SegmentationClass/\n",
    "  ‚îú‚îÄ‚îÄ ImageSets/Segmentation/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4b3eb",
   "metadata": {},
   "source": [
    "## 3. Configure Dataset Paths\n",
    "Update the paths below to point to your VOC2012 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/path/to/VOCdevkit/VOC2012/JPEGImages'\n",
    "label_dir = '/path/to/VOCdevkit/VOC2012/SegmentationClass'\n",
    "train_list = '/path/to/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt'\n",
    "val_list = '/path/to/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pascal VOC class names\n",
    "PASCAL_VOC_CLASSES = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "    'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
    "    'horse', 'motorbike', 'person', 'pottedplant', 'sheep',\n",
    "    'sofa', 'train', 'tvmonitor'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c5432",
   "metadata": {},
   "source": [
    "# Device configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e34f0",
   "metadata": {},
   "source": [
    "## 4. Visualize a Sample Image and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a67a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def visualize_voc_samples(num_samples=3):\n",
    "    \"\"\"Visualize random samples from VOC dataset.\"\"\"\n",
    "    sample_images = random.sample(\n",
    "        [f for f in os.listdir(image_dir) if f.endswith('.jpg')],\n",
    "        num_samples\n",
    "    )\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, img_name in enumerate(sample_images):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        label_path = os.path.join(label_dir, img_name.replace('.jpg', '.png'))\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        label = Image.open(label_path)\n",
    "        \n",
    "        axes[idx, 0].imshow(img)\n",
    "        axes[idx, 0].set_title(f'Image: {img_name}')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(label, cmap='tab20', vmin=0, vmax=20)\n",
    "        axes[idx, 1].set_title('Segmentation Label')\n",
    "        axes[idx, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "visualize_voc_samples(num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33dc01",
   "metadata": {},
   "source": [
    "## 5. Train the Piecewise Model\n",
    "This uses the implementation from `Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation` (model, trainer, dataset classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63991412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from piecewise_training.model import PiecewiseTrainedModel\n",
    "from piecewise_training.trainer import PiecewiseTrainer\n",
    "from piecewise_training.dataset import SegmentationDataset, RandomHorizontalFlip\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Config\n",
    "num_classes = 21\n",
    "batch_size = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Datasets\n",
    "train_dataset = SegmentationDataset(image_dir=image_dir, label_dir=label_dir, transform=RandomHorizontalFlip(), image_size=(512, 512))\n",
    "val_dataset = SegmentationDataset(image_dir=image_dir, label_dir=label_dir, image_size=(512, 512))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Model and trainer\n",
    "model = PiecewiseTrainedModel(num_classes=num_classes, crf_iterations=10, use_crf=True)\n",
    "trainer = PiecewiseTrainer(model=model, device=device, num_classes=num_classes, learning_rate=1e-3, weight_decay=5e-4)\n",
    "\n",
    "print(\"Model and trainer ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd534c",
   "metadata": {},
   "source": [
    "## 6. Train the Piecewise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING PIECEWISE TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train with piecewise strategy\n",
    "history = trainer.train_piecewise(\n",
    "    train_loader=train_loader,\n",
    "    stage1_epochs=20,  # Train unary network\n",
    "    stage2_epochs=5,   # Train CRF parameters\n",
    "    stage3_epochs=10,  # Joint fine-tuning\n",
    "    val_loader=val_loader\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_save_path = 'piecewise_model_final.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"\\n‚úÖ Model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40465eb1",
   "metadata": {},
   "source": [
    "## 7. Generate Comprehensive Evaluation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d14f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING COMPREHENSIVE EVALUATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from src.piecewise_training.visualization import ComprehensiveVisualizer\n",
    "import numpy as np\n",
    "\n",
    "# Create visualizer\n",
    "visualizer = ComprehensiveVisualizer(\n",
    "    num_classes=num_classes,\n",
    "    class_names=PASCAL_VOC_CLASSES\n",
    ")\n",
    "\n",
    "# Collect validation metrics\n",
    "print(\"\\nüìä Collecting validation metrics...\")\n",
    "model.eval()\n",
    "\n",
    "confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "sample_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        unary_output, crf_output = model(images, apply_crf=True)\n",
    "        unary_pred = unary_output.argmax(1)\n",
    "        crf_pred = crf_output.argmax(1) if crf_output is not None else unary_pred\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        for i in range(num_classes):\n",
    "            for j in range(num_classes):\n",
    "                mask = labels != 255  # Ignore index\n",
    "                confusion_matrix[i, j] += (\n",
    "                    (labels[mask] == i) & (crf_pred[mask] == j)\n",
    "                ).sum().item()\n",
    "        \n",
    "        # Collect sample predictions (first 10 batches)\n",
    "        if batch_idx < 10:\n",
    "            for b in range(min(3, images.shape[0])):\n",
    "                sample_predictions.append({\n",
    "                    'image': images[b],\n",
    "                    'gt': labels[b],\n",
    "                    'unary_pred': unary_pred[b],\n",
    "                    'crf_pred': crf_pred[b],\n",
    "                    'pred': crf_pred[b]\n",
    "                })\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"   Processed {batch_idx}/{len(val_loader)} batches...\")\n",
    "\n",
    "# Compute final metrics\n",
    "print(\"\\nüìà Computing final metrics...\")\n",
    "iou_per_class = visualizer._compute_iou_from_cm(confusion_matrix)\n",
    "mean_iou = np.nanmean(iou_per_class)\n",
    "\n",
    "final_metrics = {\n",
    "    'mIoU': mean_iou,\n",
    "    'Pixel Acc': confusion_matrix.diagonal().sum() / confusion_matrix.sum()\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Final mIoU: {mean_iou:.4f}\")\n",
    "print(f\"‚úÖ Pixel Accuracy: {final_metrics['Pixel Acc']:.4f}\")\n",
    "\n",
    "# Generate complete report\n",
    "print(\"\\nüé® Generating visualizations...\")\n",
    "results_dir = 'training_results'\n",
    "Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "visualizer.generate_full_report(\n",
    "    history=history,\n",
    "    final_metrics=final_metrics,\n",
    "    confusion_matrix=confusion_matrix,\n",
    "    sample_predictions=sample_predictions,\n",
    "    save_dir=results_dir\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Complete report saved to: {results_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d357b",
   "metadata": {},
   "source": [
    "## 8. Display Individual Visualizations in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Training Curves\n",
    "print(\"\\nüìä Training Curves:\")\n",
    "visualizer.plot_training_curves(history)\n",
    "\n",
    "# 8.2 Metrics Table\n",
    "print(\"\\nüìã Metrics Summary:\")\n",
    "visualizer.generate_metrics_table(history, final_metrics)\n",
    "\n",
    "# 8.3 Confusion Matrix\n",
    "print(\"\\nüî¢ Confusion Matrix:\")\n",
    "visualizer.plot_confusion_matrix(confusion_matrix)\n",
    "\n",
    "# 8.4 Per-Class IoU\n",
    "print(\"\\nüìä Per-Class IoU:\")\n",
    "visualizer.plot_per_class_iou(iou_per_class)\n",
    "\n",
    "# 8.5 Sample Predictions\n",
    "print(\"\\nüñºÔ∏è Sample Predictions:\")\n",
    "visualizer.visualize_predictions_grid(sample_predictions[:6])\n",
    "\n",
    "# 8.6 CRF Comparison\n",
    "print(\"\\nüîç CRF Refinement Comparison:\")\n",
    "visualizer.plot_crf_comparison(sample_predictions[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cebac",
   "metadata": {},
   "source": [
    "## 9. Detailed Per-Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2077b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-CLASS PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create detailed table\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "class_performance = []\n",
    "for idx, class_name in enumerate(PASCAL_VOC_CLASSES):\n",
    "    if not np.isnan(iou_per_class[idx]):\n",
    "        tp = confusion_matrix[idx, idx]\n",
    "        fp = confusion_matrix[:, idx].sum() - tp\n",
    "        fn = confusion_matrix[idx, :].sum() - tp\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        class_performance.append({\n",
    "            'Class': class_name,\n",
    "            'IoU': iou_per_class[idx],\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'Support': int(tp + fn)\n",
    "        })\n",
    "\n",
    "df_performance = pd.DataFrame(class_performance)\n",
    "df_performance = df_performance.sort_values('IoU', ascending=False)\n",
    "\n",
    "print(tabulate(df_performance, headers='keys', tablefmt='grid', floatfmt='.4f', showindex=False))\n",
    "\n",
    "# Save to CSV\n",
    "df_performance.to_csv(f'{results_dir}/per_class_performance.csv', index=False)\n",
    "print(f\"\\n‚úÖ Saved to: {results_dir}/per_class_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826a444",
   "metadata": {},
   "source": [
    "## 10. Run Inference on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNNING INFERENCE ON TEST IMAGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def run_inference_on_image(image_path, model, device, visualize=True):\n",
    "    \"\"\"Run inference on a single image.\"\"\"\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    original_size = image.size\n",
    "    \n",
    "    # Resize and normalize\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        unary_output, crf_output = model(image_tensor, apply_crf=True)\n",
    "        \n",
    "        unary_pred = unary_output.argmax(1).squeeze(0)\n",
    "        crf_pred = crf_output.argmax(1).squeeze(0) if crf_output is not None else unary_pred\n",
    "    \n",
    "    if visualize:\n",
    "        # Visualize results\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Unary prediction\n",
    "        colors = plt.cm.get_cmap('tab20', num_classes)\n",
    "        unary_colored = colors(unary_pred.cpu().numpy())[:, :, :3]\n",
    "        axes[1].imshow(unary_colored)\n",
    "        axes[1].set_title('Unary (CNN Only)', fontsize=14, fontweight='bold')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # CRF prediction\n",
    "        crf_colored = colors(crf_pred.cpu().numpy())[:, :, :3]\n",
    "        axes[2].imshow(crf_colored)\n",
    "        axes[2].set_title('CRF Refined', fontsize=14, fontweight='bold')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return unary_pred, crf_pred\n",
    "\n",
    "# Example: Run inference on a test image\n",
    "test_image_path = '/path/to/test/image.jpg'  # Update this path\n",
    "\n",
    "if os.path.exists(test_image_path):\n",
    "    print(f\"\\nüñºÔ∏è Running inference on: {test_image_path}\")\n",
    "    unary_pred, crf_pred = run_inference_on_image(test_image_path, model, device)\n",
    "    print(\"‚úÖ Inference complete!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Test image not found: {test_image_path}\")\n",
    "    print(\"Please update the path to a valid image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0721d9ba",
   "metadata": {},
   "source": [
    "## 11. Batch Inference on Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08199d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_inference(image_paths, model, device, save_dir='inference_results'):\n",
    "    \"\"\"Run inference on multiple images and save results.\"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for idx, img_path in enumerate(image_paths):\n",
    "        print(f\"\\nProcessing {idx+1}/{len(image_paths)}: {img_path}\")\n",
    "        \n",
    "        unary_pred, crf_pred = run_inference_on_image(\n",
    "            img_path, model, device, visualize=False\n",
    "        )\n",
    "        \n",
    "        # Save predictions\n",
    "        save_path = Path(save_dir) / f\"prediction_{idx:03d}.png\"\n",
    "        \n",
    "        # Convert to color image\n",
    "        colors = plt.cm.get_cmap('tab20', num_classes)\n",
    "        crf_colored = (colors(crf_pred.cpu().numpy())[:, :, :3] * 255).astype(np.uint8)\n",
    "        Image.fromarray(crf_colored).save(save_path)\n",
    "        \n",
    "        print(f\"   Saved to: {save_path}\")\n",
    "\n",
    "# Example: Process multiple test images\n",
    "test_images = [\n",
    "    '/path/to/test/image1.jpg',\n",
    "    '/path/to/test/image2.jpg',\n",
    "    '/path/to/test/image3.jpg',\n",
    "]\n",
    "\n",
    "# Uncomment to run batch inference\n",
    "# batch_inference(test_images, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a8ae7",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ Model trained successfully with piecewise strategy\n",
    "‚úÖ Final mIoU: {mean_iou:.4f}\n",
    "‚úÖ Pixel Accuracy: {final_metrics['Pixel Acc']:.4f}\n",
    "\n",
    "üìÅ Generated Files:\n",
    "   - Model: {model_save_path}\n",
    "   - Results: {results_dir}/\n",
    "     ‚îú‚îÄ‚îÄ training_curves.png\n",
    "     ‚îú‚îÄ‚îÄ metrics_summary.txt\n",
    "     ‚îú‚îÄ‚îÄ metrics_summary.csv\n",
    "     ‚îú‚îÄ‚îÄ confusion_matrix.png\n",
    "     ‚îú‚îÄ‚îÄ per_class_iou.png\n",
    "     ‚îú‚îÄ‚îÄ sample_predictions.png\n",
    "     ‚îú‚îÄ‚îÄ crf_comparison.png\n",
    "     ‚îî‚îÄ‚îÄ per_class_performance.csv\n",
    "\n",
    "üéØ Next Steps:\n",
    "   1. Review training curves and metrics\n",
    "   2. Analyze per-class performance\n",
    "   3. Run inference on your own images\n",
    "   4. Fine-tune hyperparameters if needed\n",
    "   5. Experiment with different CRF iterations\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
